{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After nolabel: 229942\n",
      "After label: 235886\n",
      "After test: 241746\n",
      "word_freq is already\n",
      "load model...\n",
      "Weight_matrix shape :  (78522, 128)\n",
      "word2vec is already.\n",
      "Length of train_sentence :  200000\n",
      "Length of train_word2idx :  200000\n",
      "Max length of train sentence :  95\n",
      "Length of test_sentence :  200000\n",
      "Length of test_word2idx :  200000\n",
      "Max length of test sentence :  95\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)          (None, 100, 128)      10050816    input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)                (None, 96, 96)        61536       embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)                (None, 92, 96)        110688      embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)                (None, 98, 96)        36960       embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)   (None, 95, 96)        0           conv1d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)   (None, 91, 96)        0           conv1d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)   (None, 96, 96)        0           conv1d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 95, 96)        0           max_pooling1d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 91, 96)        0           max_pooling1d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 96, 96)        0           max_pooling1d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                    (None, 95, 128)       115200      dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lstm_11 (LSTM)                   (None, 91, 128)       115200      dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lstm_13 (LSTM)                   (None, 96, 128)       115200      dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lstm_15 (LSTM)                   (None, 100, 128)      131584      embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                   (None, 256)           394240      lstm_9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_12 (LSTM)                   (None, 256)           394240      lstm_11[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_14 (LSTM)                   (None, 256)           394240      lstm_13[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_16 (LSTM)                   (None, 256)           394240      lstm_15[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 256)           65792       lstm_10[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 256)           65792       lstm_12[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 256)           65792       lstm_14[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 256)           65792       lstm_16[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 1024)          0           dense_8[0][0]                    \n",
      "                                                                   dense_9[0][0]                    \n",
      "                                                                   dense_10[0][0]                   \n",
      "                                                                   dense_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 1024)          0           concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 512)           524800      dropout_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 512)           0           dense_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 2)             1026        dropout_11[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 13,103,138\n",
      "Trainable params: 13,103,138\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 180000 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      "180000/180000 [==============================] - 396s - loss: 0.4737 - acc: 0.7756 - val_loss: 0.4277 - val_acc: 0.8055"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks.py:496: RuntimeWarning: Early stopping conditioned on metric `val_categorical_accuracy` which is not available. Available metrics are: loss,val_acc,acc,val_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10\n",
      "180000/180000 [==============================] - 360s - loss: 0.4168 - acc: 0.8107 - val_loss: 0.4054 - val_acc: 0.8176\n",
      "Epoch 3/10\n",
      "180000/180000 [==============================] - 356s - loss: 0.3871 - acc: 0.8282 - val_loss: 0.4163 - val_acc: 0.8103\n",
      "Epoch 4/10\n",
      "180000/180000 [==============================] - 354s - loss: 0.3578 - acc: 0.8423 - val_loss: 0.4054 - val_acc: 0.8185\n",
      "Epoch 5/10\n",
      "180000/180000 [==============================] - 354s - loss: 0.3297 - acc: 0.8578 - val_loss: 0.4196 - val_acc: 0.8169\n",
      "Epoch 6/10\n",
      "180000/180000 [==============================] - 352s - loss: 0.2965 - acc: 0.8747 - val_loss: 0.4794 - val_acc: 0.8096\n",
      "Epoch 7/10\n",
      "115200/180000 [==================>...........] - ETA: 122s - loss: 0.2635 - acc: 0.8892"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4a326f42f7f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    193\u001b[0m                           \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearlystopping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                           validation_split=0.1)\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mmodel_fi_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1118\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1315\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1316\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1298\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1299\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from CRNN_config import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "save_dict = True\n",
    "word_freq_path =  'word_freq.pk'\n",
    "\n",
    "load_word2vec = True\n",
    "word2vec_path = 'word2vec.bin'\n",
    "\n",
    "load_model_bool = False\n",
    "model_path = 'CRNN_1st.h5'\n",
    "\n",
    "nolabel = np.load(\"/home/derricksu/ML_data/hw4/train_nolabel.npy\")\n",
    "train_path = \"/home/derricksu/ML_data/hw4/train.npy\"\n",
    "train = np.load(train_path)\n",
    "test_path = \"/home/derricksu/ML_data/hw4/test.npy\"\n",
    "test = np.load(test_path)\n",
    "predict_path = \"/home/derricksu/pred/best.csv\"\n",
    "\n",
    "\"\"\"\n",
    "## for homework\n",
    "train_path = sys.argv[1]\n",
    "train=load_data(train_path,train=True)\n",
    "\n",
    "nolabel_path = sys.argv[2]\n",
    "nolabel = load_nolabel(nolabel_path)\n",
    "\n",
    "test_path = sys.argv[1]\n",
    "test = load_data(test_path,train=False)\n",
    "\n",
    "predict_path = sys.argv[2]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Record frequency of each word\n",
    "word_freq=defaultdict(int)\n",
    "\n",
    "# nolabel\n",
    "sentence = []\n",
    "for row in nolabel:\n",
    "    x = text_to_wordlist(row).split()\n",
    "    sentence.append(x)\n",
    "    for s in x:\n",
    "        word_freq[s]+=1\n",
    "\n",
    "print(\"After nolabel: %d\" % len(word_freq))\n",
    "\n",
    "# label\n",
    "X_data = train[:,1]\n",
    "y_data = train[:,0].astype('int')\n",
    "\n",
    "\n",
    "train_sentence = []\n",
    "\n",
    "for i,row in enumerate(X_data):\n",
    "    x = text_to_wordlist(row).split()\n",
    "    train_sentence.append(x)\n",
    "    for s in x:\n",
    "        word_freq[s]+=1\n",
    "print(\"After label: %d\" % len(word_freq))\n",
    "\n",
    "test_sentence = []\n",
    "for i,row in enumerate(test[1::,1]): #第一列不為name\n",
    "    x = text_to_wordlist(row).split()\n",
    "    test_sentence.append(x)\n",
    "    for s in x:\n",
    "        word_freq[s]+=1\n",
    "print(\"After test: %d\" % len(word_freq))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# produce word_freq\n",
    "if save_dict:\n",
    "    with open(word_freq_path,\"wb\") as pk:\n",
    "        pickle.dump( word_freq,pk )\n",
    "        pk.close()\n",
    "else:\n",
    "    with open(word_freq_path,\"rb\") as pk:\n",
    "        word_freq = pickle.load(pk)\n",
    "        pk.close()\n",
    "print(\"word_freq is already\")\n",
    "\n",
    "\n",
    "# produce word2vec\n",
    "if not load_word2vec:\n",
    "    w2v_st_time=time.time()\n",
    "    print(\"train word2vec...\") \n",
    "    # sg defines the training algorithm. By default (sg=0), CBOW is used. Otherwise (sg=1), skip-gram is employed. window=12\n",
    "    my_word2vec = Word2Vec(sentence + train_sentence + test_sentence, sg = 0,#window=15,\n",
    "                           iter=30, min_count=min_c,size=128,workers=16)\n",
    "    w2v_fi_time=time.time()\n",
    "    # summarize the loaded model\n",
    "    print(my_word2vec)\n",
    "    # summarize vocabulary\n",
    "    words = list(my_word2vec.wv.vocab)\n",
    "    #print(words)\n",
    "    # access vector for one word\n",
    "    print(my_word2vec['sentence'].shape)\n",
    "    # save model\n",
    "    my_word2vec.save(word2vec_path)\n",
    "else:\n",
    "    print(\"load model...\") \n",
    "    my_word2vec = Word2Vec.load(word2vec_path)\n",
    "    #print(my_word2vec)\n",
    "\n",
    "vocab = dict([(k, v.index) for k, v in my_word2vec.wv.vocab.items()])\n",
    "weight_matrix = my_word2vec.wv.syn0 #word_to_vec\n",
    "print(\"Weight_matrix shape : \" , weight_matrix.shape)\n",
    "del my_word2vec\n",
    "print(\"word2vec is already.\")\n",
    "\n",
    "\n",
    "# word to idx of train\n",
    "train_word2idx=[]\n",
    "for row in train_sentence:\n",
    "    idx = []\n",
    "    for word in row:\n",
    "        if word_freq[word]>=min_c:\n",
    "            idx.append(vocab[word])\n",
    "    train_word2idx.append(idx)\n",
    "\n",
    "print(\"Length of train_sentence : \",len(train_sentence))\n",
    "print(\"Length of train_word2idx : \",len(train_word2idx))\n",
    "\n",
    "max_len = 0\n",
    "for row in train_word2idx:\n",
    "    if max_len <len(row):\n",
    "        max_len = len(row)\n",
    "print(\"Max length of train sentence : \",max_len)\n",
    "\n",
    "# word to idx of test\n",
    "test_word2idx=[]\n",
    "for row in test_sentence:\n",
    "    idx = []\n",
    "    for word in row:\n",
    "        if word_freq[word]>=min_c:\n",
    "            idx.append(vocab[word])\n",
    "    test_word2idx.append(idx)\n",
    "print(\"Length of test_sentence : \",len(test_sentence))\n",
    "print(\"Length of test_word2idx : \",len(test_word2idx))\n",
    "\n",
    "max_len = 0\n",
    "for row in train_word2idx:\n",
    "    if max_len <len(row):\n",
    "        max_len = len(row)\n",
    "print(\"Max length of test sentence : \",max_len)\n",
    "\n",
    "\n",
    "\n",
    "#import keras\n",
    "from keras import utils\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "Y_train = utils.to_categorical(y_data ,2)\n",
    "X_train = train_word2idx\n",
    "X_test = test_word2idx\n",
    "\n",
    "\n",
    "max_review_length = 100\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "\n",
    "n_batch = 256\n",
    "n_epoch = 10\n",
    "\n",
    "if load_model_bool:\n",
    "    model = load_model(model_path)\n",
    "else:\n",
    "    from keras.callbacks import EarlyStopping , History\n",
    "    model_st_time=time.time()\n",
    "    model = build(weight_matrix,vocab,max_review_length)\n",
    "\n",
    "    earlystopping=EarlyStopping(monitor='val_categorical_accuracy', patience=3, verbose=0, mode='auto')\n",
    "    history = History()\n",
    "\n",
    "    hist_lstm = model.fit(X_train , Y_train ,\n",
    "                          batch_size = n_batch,epochs=n_epoch,\n",
    "                          callbacks=[earlystopping,history],\n",
    "                          validation_split=0.1)\n",
    "\n",
    "    model_fi_time=time.time()\n",
    "    \n",
    "\"\"\"    \n",
    "pred_y = model.predict(X_test,batch_size=n_batch)\n",
    "print(\"Shape of predict of test : \",pred_y.shape)\n",
    "\n",
    "with open(predict_path , \"w\" , encoding = \"utf-8\") as f :\n",
    "    f.write(\"id,label\\n\")\n",
    "    for i ,pre in enumerate(pred_y):\n",
    "        f.write( \"{0},{1}\\n\".format( i , np.argmax(pre) ) )\n",
    "    f.close()\n",
    "\"\"\"\n",
    "print(\"Finish.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_4 (InputLayer)             (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)          (None, 100, 128)      10050816    input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)               (None, 96, 96)        61536       embedding_4[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)               (None, 92, 96)        110688      embedding_4[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)               (None, 98, 96)        36960       embedding_4[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D)  (None, 95, 96)        0           conv1d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D)  (None, 91, 96)        0           conv1d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D)  (None, 96, 96)        0           conv1d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)             (None, 95, 96)        0           max_pooling1d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)             (None, 91, 96)        0           max_pooling1d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)             (None, 96, 96)        0           max_pooling1d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "lstm_25 (LSTM)                   (None, 95, 128)       115200      dropout_19[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lstm_27 (LSTM)                   (None, 91, 128)       115200      dropout_20[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lstm_29 (LSTM)                   (None, 96, 128)       115200      dropout_21[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lstm_31 (LSTM)                   (None, 100, 128)      131584      embedding_4[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_26 (LSTM)                   (None, 256)           394240      lstm_25[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_28 (LSTM)                   (None, 256)           394240      lstm_27[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_30 (LSTM)                   (None, 256)           394240      lstm_29[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_32 (LSTM)                   (None, 256)           394240      lstm_31[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_22 (Dense)                 (None, 256)           65792       lstm_26[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_23 (Dense)                 (None, 256)           65792       lstm_28[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_24 (Dense)                 (None, 256)           65792       lstm_30[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_25 (Dense)                 (None, 256)           65792       lstm_32[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 1024)          0           dense_22[0][0]                   \n",
      "                                                                   dense_23[0][0]                   \n",
      "                                                                   dense_24[0][0]                   \n",
      "                                                                   dense_25[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)             (None, 1024)          0           concatenate_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_26 (Dense)                 (None, 512)           524800      dropout_22[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)             (None, 512)           0           dense_26[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_28 (Dense)                 (None, 2)             1026        dropout_23[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 13,103,138\n",
      "Trainable params: 13,103,138\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 180000 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      "180000/180000 [==============================] - 410s - loss: 0.4732 - acc: 0.7758 - val_loss: 0.4213 - val_acc: 0.8066\n",
      "Epoch 2/10\n",
      "180000/180000 [==============================] - 362s - loss: 0.4160 - acc: 0.8106 - val_loss: 0.4056 - val_acc: 0.8166\n",
      "Epoch 3/10\n",
      "180000/180000 [==============================] - 362s - loss: 0.3874 - acc: 0.8278 - val_loss: 0.3998 - val_acc: 0.8189\n",
      "Epoch 4/10\n",
      "180000/180000 [==============================] - 362s - loss: 0.3598 - acc: 0.8425 - val_loss: 0.3994 - val_acc: 0.8216\n",
      "Epoch 5/10\n",
      "180000/180000 [==============================] - 362s - loss: 0.3304 - acc: 0.8578 - val_loss: 0.4256 - val_acc: 0.8167\n",
      "Epoch 6/10\n",
      "180000/180000 [==============================] - 362s - loss: 0.3003 - acc: 0.8729 - val_loss: 0.4550 - val_acc: 0.8114\n",
      "Epoch 7/10\n",
      "180000/180000 [==============================] - 360s - loss: 0.2692 - acc: 0.8864 - val_loss: 0.4844 - val_acc: 0.8064\n",
      "Epoch 8/10\n",
      "180000/180000 [==============================] - 360s - loss: 0.2414 - acc: 0.8992 - val_loss: 0.5367 - val_acc: 0.7986\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping , History\n",
    "model_st_time=time.time()\n",
    "model = build(weight_matrix,vocab,max_review_length)\n",
    "\n",
    "earlystopping=EarlyStopping(monitor='val_acc', patience=3, verbose=0, mode='auto')\n",
    "history = History()\n",
    "\n",
    "hist_lstm = model.fit(X_train , Y_train ,\n",
    "                      batch_size = n_batch,epochs=n_epoch,\n",
    "                      callbacks=[earlystopping,history],\n",
    "                      validation_split=0.1)\n",
    "\n",
    "model_fi_time=time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAD8CAYAAABaSfxxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+P8zIooUacCllwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff59caf3d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hist_dict = hist_lstm.history\n",
    "\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "ax = fig.add_subplot(111)\n",
    "for key in ['acc' , 'val_acc']:\n",
    "    y = hist_dict[key]\n",
    "    ax.plot(y[0:4],label=key)\n",
    "    max_index = 3\n",
    "    ax.annotate('{0:.3f}'.format(y[max_index]) , xy =(max_index , y[max_index]-0.005),horizontalalignment='center' )\n",
    "\n",
    "plt.legend()    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461.07216715812683"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"time for training a word2vec  :\",w2v_fi_time-w2v_st_time)\n",
    "print(\"time for training a RNN model :\",model_fi_time-model_st_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 請說明你實作的 BOW model，其模型架構、訓練過程和準確率為何？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "200000 test sequences\n",
      "2 classes\n",
      "Vectorizing sequence data...\n",
      "x_train shape: (200000, 10000)\n",
      "x_test shape: (200000, 10000)\n",
      "Convert class vector to binary class matrix (for use with categorical_crossentropy)\n",
      "y_train shape: (200000, 2)\n",
      "y_test shape: (2246, 46)\n",
      "Building model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 512)               5120512   \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 2)                 514       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 5,252,354\n",
      "Trainable params: 5,252,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 180000 samples, validate on 20000 samples\n",
      "Epoch 1/5\n",
      "180000/180000 [==============================] - 79s - loss: 0.4813 - acc: 0.7730 - val_loss: 0.4518 - val_acc: 0.7930\n",
      "Epoch 2/5\n",
      "180000/180000 [==============================] - 53s - loss: 0.4072 - acc: 0.8171 - val_loss: 0.4458 - val_acc: 0.7978\n",
      "Epoch 3/5\n",
      "180000/180000 [==============================] - 54s - loss: 0.3417 - acc: 0.8525 - val_loss: 0.4591 - val_acc: 0.7954\n",
      "Epoch 4/5\n",
      "180000/180000 [==============================] - 54s - loss: 0.2803 - acc: 0.8822 - val_loss: 0.4937 - val_acc: 0.7907\n",
      "Epoch 5/5\n",
      "180000/180000 [==============================] - 54s - loss: 0.2315 - acc: 0.9059 - val_loss: 0.5352 - val_acc: 0.7905\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'pridect'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-21069c8a20e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                     validation_split=0.1)\n\u001b[0;32m---> 57\u001b[0;31m pred_y = model.pridect(x_test,\n\u001b[0m\u001b[1;32m     58\u001b[0m                        batch_size=batch_size, verbose=1)\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'pridect'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import reuters\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "max_words = 10000 #241746\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "print('Loading data...')\n",
    "x_train = X_data\n",
    "y_train = y_data\n",
    "x_test = test[1::,1]\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "num_classes = 2\n",
    "print(num_classes, 'classes')\n",
    "\n",
    "print('Vectorizing sequence data...')\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "x_train = tokenizer.texts_to_matrix(x_train, mode='binary')\n",
    "x_test = tokenizer.texts_to_matrix(x_test, mode='binary')\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Convert class vector to binary class matrix '\n",
    "      '(for use with categorical_crossentropy)')\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "print('Building model...')\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199712/200000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "pred_y = model.predict(x_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "\n",
    "predict_path='/home/derricksu/pred/BOW.csv'\n",
    "with open(predict_path , \"w\" , encoding = \"utf-8\") as f :\n",
    "    f.write(\"id,label\\n\")\n",
    "    for i ,pre in enumerate(pred_y):\n",
    "        f.write( \"{0},{1}\\n\".format( i , np.argmax(pre) ) )\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAD8CAYAAABaSfxxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff475e71cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hist_dict = history.history\n",
    "\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "ax = fig.add_subplot(111)\n",
    "for key in ['acc' , 'val_acc']:\n",
    "    y = hist_dict[key]\n",
    "    ax.plot(y[0:4],label=key)\n",
    "    max_index = 3\n",
    "    ax.annotate('{0:.3f}'.format(y[max_index]) , xy =(max_index , y[max_index]-0.005),horizontalalignment='center' )\n",
    "\n",
    "plt.legend()    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 100, 128)          10050816  \n",
      "_________________________________________________________________\n",
      "lstm_37 (LSTM)               (None, 100, 128)          131584    \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 100, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_38 (LSTM)               (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 10,840,066\n",
      "Trainable params: 10,840,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 180000 samples, validate on 20000 samples\n",
      "Epoch 1/5\n",
      "180000/180000 [==============================] - 138s - loss: 0.4818 - categorical_accuracy: 0.7700 - val_loss: 0.4285 - val_categorical_accuracy: 0.8023\n",
      "Epoch 2/5\n",
      "180000/180000 [==============================] - 105s - loss: 0.4244 - categorical_accuracy: 0.8061 - val_loss: 0.4059 - val_categorical_accuracy: 0.8142\n",
      "Epoch 3/5\n",
      "180000/180000 [==============================] - 105s - loss: 0.3962 - categorical_accuracy: 0.8231 - val_loss: 0.4017 - val_categorical_accuracy: 0.8153\n",
      "Epoch 4/5\n",
      "180000/180000 [==============================] - 105s - loss: 0.3729 - categorical_accuracy: 0.8355 - val_loss: 0.4043 - val_categorical_accuracy: 0.8192\n",
      "Epoch 5/5\n",
      "180000/180000 [==============================] - 105s - loss: 0.3504 - categorical_accuracy: 0.8470 - val_loss: 0.4064 - val_categorical_accuracy: 0.8190\n",
      "Shape of predict of test :  (200000, 2)\n"
     ]
    }
   ],
   "source": [
    "def RNN(weight_matrix , vocab,max_review_length):\n",
    "    embedding_vecor_length = weight_matrix.shape[1]\n",
    "    word_total_index = len(vocab)\n",
    "\n",
    "    forget_bias_bool=True #default is False\n",
    "    recu_drop_rate=0.2\n",
    "    drop_rate=0.2\n",
    "    back_bool=False #default False\n",
    "    unroll_bool=True #default is False. This can speed up but consume more memory\n",
    "    multi_layer_bool=True #default False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(word_total_index, embedding_vecor_length, input_length=max_review_length,\n",
    "                       weights = [weight_matrix]))\n",
    "    \n",
    "    model.add(LSTM(128,\n",
    "                  unit_forget_bias=forget_bias_bool,\n",
    "                  recurrent_dropout=recu_drop_rate,\n",
    "                  dropout=drop_rate,\n",
    "                  go_backwards=back_bool,\n",
    "                  unroll=unroll_bool,\n",
    "                  return_sequences=multi_layer_bool )) \n",
    "                   # Control output of this layer , return a decoded sequence whose dimension is same as input\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(256,\n",
    "                  unit_forget_bias=forget_bias_bool,\n",
    "                  recurrent_dropout=recu_drop_rate,\n",
    "                  dropout=drop_rate,\n",
    "                  go_backwards=False,\n",
    "                  unroll=unroll_bool))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "    print(model.summary())\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model_rnn = RNN(weight_matrix , vocab,max_review_length)\n",
    "n_batch = 256\n",
    "n_epoch = 10\n",
    "\n",
    "earlystopping=EarlyStopping(monitor='val_categorical_accuracy', patience=3, verbose=0, mode='auto')\n",
    "history = History()\n",
    "\n",
    "hist_rnn= model_rnn.fit(X_train , Y_train ,\n",
    "                      batch_size = n_batch,epochs=5,\n",
    "                      callbacks=[earlystopping,history],\n",
    "                      validation_split=0.1)\n",
    "\n",
    "pred_y = model_rnn.predict(X_test,batch_size=n_batch)\n",
    "print(\"Shape of predict of test : \",pred_y.shape)\n",
    "predict_path = \"/home/derricksu/pred/lstm_12_7.csv\"\n",
    "\n",
    "with open(predict_path , \"w\" , encoding = \"utf-8\") as f :\n",
    "    f.write(\"id,label\\n\")\n",
    "    for i ,pre in enumerate(pred_y):\n",
    "        f.write( \"{0},{1}\\n\".format( i , np.argmax(pre) ) )\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn.save(\"lstm_best.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-13444f5cd43c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_rnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lstm.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_model' is not defined"
     ]
    }
   ],
   "source": [
    "plot_model(model_rnn,tofile='lstm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAD8CAYAAABaSfxxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff42e7c5978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hist_dict = hist_rnn.history\n",
    "\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "ax = fig.add_subplot(111)\n",
    "for key in ['categorical_accuracy' , 'val_categorical_accuracy']:\n",
    "    y = hist_dict[key]\n",
    "    ax.plot(y,label=key)\n",
    "    max_index = 4\n",
    "    ax.annotate('{0:.3f}'.format(y[max_index]) , xy =(max_index , y[max_index]-0.005),horizontalalignment='center' )\n",
    "\n",
    "plt.legend()    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 請比較bag of word與RNN兩種不同model對於\"today is a good day, but it is hot\"與\"today is hot, but it is a good day\"這兩句的情緒分數，並討論造成差異的原因。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proce(nolabel,word_freq,vocab):\n",
    "    min_c = 3\n",
    "    sentence = []\n",
    "    for row in nolabel:\n",
    "        x = text_to_wordlist(row).split()\n",
    "        sentence.append(x)\n",
    "    train_word2idx=[]\n",
    "    for row in sentence:\n",
    "        idx = []\n",
    "        for word in row:\n",
    "            if word_freq[word]>=min_c:\n",
    "                idx.append(vocab[word])\n",
    "        train_word2idx.append(idx)\n",
    "    train_word2idx = sequence.pad_sequences(train_word2idx, maxlen=max_review_length)\n",
    "    return train_word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw=[\"today is a good day, but it is hot\",\"today is hot, but it is a good day\"]\n",
    "\n",
    "hw_bow = tokenizer.texts_to_matrix(hw, mode='binary')\n",
    "\n",
    "hw_rnn = proce(hw,word_freq,vocab)\n",
    "\n",
    "vec_bow = model.predict(hw_bow)\n",
    "\n",
    "vec_rnn = model_rnn.predict(hw_rnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hw_bow.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38304621,  0.61695379],\n",
       "       [ 0.38304621,  0.61695379]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3894341 ,  0.6105659 ],\n",
       "       [ 0.01503595,  0.98496407]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from CRNN_config_nocomma import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_wordlist(text, remove_stopwords=False, stem_words=False,comma=True):\n",
    "    # Clean the text, with the option to remove stopwords and to stem words.\n",
    "    import re\n",
    "    # Convert words to lower case and split them\n",
    "    text = text.lower().split()\n",
    "\n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "\n",
    "    # Clean the text\n",
    "    if not comma:\n",
    "        text = re.sub(r\"[,+\\$&^!:;.\\/'-=?]\", \" \", text) # origin is [^A-Za-z0-9^,!.\\/'+-=?]\n",
    "    else:\n",
    "        pass\n",
    "    # Optionally, shorten words to their stems\n",
    "    if stem_words:\n",
    "        text = text.split()\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        stemmed_words = [stemmer.stem(word) for word in text]\n",
    "        text = \" \".join(stemmed_words)\n",
    "    \n",
    "    # Return a list of words\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"wer qwe qw 123 &&$$ ''^^: ,12d3 , ,+ ,\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_wordlist(\"wer qwe qw 123 &&$$ ''^^: ,12d3 , ,+  ,\",comma=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1234 gs  df       '"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "text = \"1234 gs__df*\\ ><,.\"\n",
    "re.sub(r\"[,:\\\\\\/\\_^.$%#><+-/\\?\\=*]\", \" \", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 比較有無標點符號"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After nolabel: 244275\n",
      "After label: 250590\n",
      "After test: 256792\n",
      "word_freq is already\n",
      "train word2vec...\n",
      "Word2Vec(vocab=82670, size=128, alpha=0.025)\n",
      "(128,)\n",
      "Weight_matrix shape :  (82670, 128)\n",
      "word2vec is already.\n",
      "Length of train_sentence :  200000\n",
      "Length of train_word2idx :  200000\n",
      "Max length of train sentence :  40\n",
      "Length of test_sentence :  200000\n",
      "Length of test_word2idx :  200000\n",
      "Max length of test sentence :  40\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 128)          10581760  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 128)          131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 11,371,010\n",
      "Trainable params: 11,371,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 180000 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      "180000/180000 [==============================] - 112s - loss: 0.4817 - categorical_accuracy: 0.7697 - val_loss: 0.4284 - val_categorical_accuracy: 0.8031\n",
      "Epoch 2/10\n",
      "180000/180000 [==============================] - 104s - loss: 0.4214 - categorical_accuracy: 0.8089 - val_loss: 0.4032 - val_categorical_accuracy: 0.8179\n",
      "Epoch 3/10\n",
      "180000/180000 [==============================] - 103s - loss: 0.3924 - categorical_accuracy: 0.8251 - val_loss: 0.3987 - val_categorical_accuracy: 0.8222\n",
      "Epoch 4/10\n",
      "180000/180000 [==============================] - 103s - loss: 0.3682 - categorical_accuracy: 0.8388 - val_loss: 0.3938 - val_categorical_accuracy: 0.8236\n",
      "Epoch 5/10\n",
      "180000/180000 [==============================] - 104s - loss: 0.3454 - categorical_accuracy: 0.8507 - val_loss: 0.4039 - val_categorical_accuracy: 0.8227\n",
      "Epoch 6/10\n",
      "180000/180000 [==============================] - 104s - loss: 0.3231 - categorical_accuracy: 0.8624 - val_loss: 0.4213 - val_categorical_accuracy: 0.8199\n",
      "Epoch 7/10\n",
      "180000/180000 [==============================] - 104s - loss: 0.3042 - categorical_accuracy: 0.8708 - val_loss: 0.4331 - val_categorical_accuracy: 0.8167\n",
      "Epoch 8/10\n",
      "180000/180000 [==============================] - 105s - loss: 0.2874 - categorical_accuracy: 0.8790 - val_loss: 0.4869 - val_categorical_accuracy: 0.8160\n",
      "Shape of predict of test :  (200000, 2)\n",
      "/home/derricksu/pred/withcamma.csv\n",
      "length of vocab :  82670\n"
     ]
    }
   ],
   "source": [
    "## 有標點符號\n",
    "\n",
    "from CRNN_config_nocomma import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "save_dict = False\n",
    "word_freq_path =  'word_freq.pk'\n",
    "\n",
    "load_word2vec = False\n",
    "word2vec_path = 'word2vec.bin'\n",
    "\n",
    "load_model_bool = False\n",
    "model_path = 'CRNN_1st.h5'\n",
    "\n",
    "nolabel = np.load(\"/home/derricksu/ML_data/hw4/train_nolabel.npy\")\n",
    "train_path = \"/home/derricksu/ML_data/hw4/train.npy\"\n",
    "train = np.load(train_path)\n",
    "test_path = \"/home/derricksu/ML_data/hw4/test.npy\"\n",
    "test = np.load(test_path)\n",
    "predict_path = \"/home/derricksu/pred/withcamma.csv\"\n",
    "\n",
    "\"\"\"\n",
    "## for homework\n",
    "train_path = sys.argv[1]\n",
    "train=load_data(train_path,train=True)\n",
    "\n",
    "nolabel_path = sys.argv[2]\n",
    "nolabel = load_nolabel(nolabel_path)\n",
    "\n",
    "test_path = sys.argv[1]\n",
    "test = load_data(test_path,train=False)\n",
    "\n",
    "predict_path = sys.argv[2]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Record frequency of each word\n",
    "word_freq=defaultdict(int)\n",
    "\n",
    "# nolabel\n",
    "sentence = []\n",
    "for row in nolabel:\n",
    "    x = text_to_wordlist(row,comma=True).split()\n",
    "    sentence.append(x)\n",
    "    for s in x:\n",
    "        word_freq[s]+=1\n",
    "\n",
    "print(\"After nolabel: %d\" % len(word_freq))\n",
    "\n",
    "# label\n",
    "X_data = train[:,1]\n",
    "y_data = train[:,0].astype('int')\n",
    "\n",
    "\n",
    "train_sentence = []\n",
    "\n",
    "for i,row in enumerate(X_data):\n",
    "    x = text_to_wordlist(row,comma=True).split()\n",
    "    train_sentence.append(x)\n",
    "    for s in x:\n",
    "        word_freq[s]+=1\n",
    "print(\"After label: %d\" % len(word_freq))\n",
    "\n",
    "test_sentence = []\n",
    "for i,row in enumerate(test[1::,1]): #第一列不為name\n",
    "    x = text_to_wordlist(row,comma=True).split()\n",
    "    test_sentence.append(x)\n",
    "    for s in x:\n",
    "        word_freq[s]+=1\n",
    "print(\"After test: %d\" % len(word_freq))\n",
    "\n",
    "\n",
    "print(\"word_freq is already\")\n",
    "\n",
    "\n",
    "# produce word2vec\n",
    "if not load_word2vec:\n",
    "    print(\"train word2vec...\") \n",
    "    # sg defines the training algorithm. By default (sg=0), CBOW is used. Otherwise (sg=1), skip-gram is employed. window=12\n",
    "    my_word2vec = Word2Vec(sentence + train_sentence + test_sentence, sg = 0,#window=15,\n",
    "                           iter=30, min_count=min_c,size=128,workers=16)\n",
    "    # summarize the loaded model\n",
    "    print(my_word2vec)\n",
    "    # summarize vocabulary\n",
    "    words = list(my_word2vec.wv.vocab)\n",
    "    #print(words)\n",
    "    # access vector for one word\n",
    "    print(my_word2vec['sentence'].shape)\n",
    "    # save model\n",
    "    #my_word2vec.save(word2vec_path)\n",
    "else:\n",
    "    print(\"load model...\") \n",
    "    my_word2vec = Word2Vec.load(word2vec_path)\n",
    "    #print(my_word2vec)\n",
    "\n",
    "vocab = dict([(k, v.index) for k, v in my_word2vec.wv.vocab.items()])\n",
    "weight_matrix = my_word2vec.wv.syn0 #word_to_vec\n",
    "print(\"Weight_matrix shape : \" , weight_matrix.shape)\n",
    "del my_word2vec\n",
    "print(\"word2vec is already.\")\n",
    "\n",
    "\n",
    "# word to idx of train\n",
    "train_word2idx=[]\n",
    "for row in train_sentence:\n",
    "    idx = []\n",
    "    for word in row:\n",
    "        if word_freq[word]>=min_c:\n",
    "            idx.append(vocab[word])\n",
    "    train_word2idx.append(idx)\n",
    "\n",
    "print(\"Length of train_sentence : \",len(train_sentence))\n",
    "print(\"Length of train_word2idx : \",len(train_word2idx))\n",
    "\n",
    "max_len = 0\n",
    "for row in train_word2idx:\n",
    "    if max_len <len(row):\n",
    "        max_len = len(row)\n",
    "print(\"Max length of train sentence : \",max_len)\n",
    "\n",
    "# word to idx of test\n",
    "test_word2idx=[]\n",
    "for row in test_sentence:\n",
    "    idx = []\n",
    "    for word in row:\n",
    "        if word_freq[word]>=min_c:\n",
    "            idx.append(vocab[word])\n",
    "    test_word2idx.append(idx)\n",
    "print(\"Length of test_sentence : \",len(test_sentence))\n",
    "print(\"Length of test_word2idx : \",len(test_word2idx))\n",
    "\n",
    "max_len = 0\n",
    "for row in train_word2idx:\n",
    "    if max_len <len(row):\n",
    "        max_len = len(row)\n",
    "print(\"Max length of test sentence : \",max_len)\n",
    "\n",
    "\n",
    "\n",
    "#import keras\n",
    "from keras import utils\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "Y_train = utils.to_categorical(y_data ,2)\n",
    "X_train = train_word2idx\n",
    "X_test = test_word2idx\n",
    "\n",
    "\n",
    "max_review_length = 100\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "\n",
    "n_batch = 256\n",
    "n_epoch = 10\n",
    "\n",
    "\n",
    "from keras.callbacks import EarlyStopping , History\n",
    "model = build(weight_matrix,vocab,max_review_length)\n",
    "earlystopping=EarlyStopping(monitor='val_categorical_accuracy', patience=3, verbose=0, mode='auto')\n",
    "history = History()\n",
    "\n",
    "hist_lstm_1 = model.fit(X_train , Y_train ,\n",
    "                      batch_size = n_batch,epochs=n_epoch,\n",
    "                      callbacks=[earlystopping,history],\n",
    "                      validation_split=0.1)\n",
    "\n",
    "pred_y = model.predict(X_test,batch_size=n_batch)\n",
    "print(\"Shape of predict of test : \",pred_y.shape)\n",
    "\n",
    "print(predict_path)\n",
    "with open(predict_path , \"w\" , encoding = \"utf-8\") as f :\n",
    "    f.write(\"id,label\\n\")\n",
    "    for i ,pre in enumerate(pred_y):\n",
    "        f.write( \"{0},{1}\\n\".format( i , np.argmax(pre) ) )\n",
    "    f.close()\n",
    "print(\"length of vocab : \",len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After nolabel: 230188\n",
      "After label: 236099\n",
      "After test: 241874\n",
      "word_freq is already\n",
      "train word2vec...\n",
      "Word2Vec(vocab=78930, size=128, alpha=0.025)\n",
      "(128,)\n",
      "Weight_matrix shape :  (78930, 128)\n",
      "word2vec is already.\n",
      "Length of train_sentence :  200000\n",
      "Length of train_word2idx :  200000\n",
      "Max length of train sentence :  39\n",
      "Length of test_sentence :  200000\n",
      "Length of test_word2idx :  200000\n",
      "Max length of test sentence :  39\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 128)          10103040  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 128)          131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 10,892,290\n",
      "Trainable params: 10,892,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 180000 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      "180000/180000 [==============================] - 113s - loss: 0.4853 - categorical_accuracy: 0.7681 - val_loss: 0.4312 - val_categorical_accuracy: 0.8031\n",
      "Epoch 2/10\n",
      "180000/180000 [==============================] - 105s - loss: 0.4273 - categorical_accuracy: 0.8051 - val_loss: 0.4183 - val_categorical_accuracy: 0.8117\n",
      "Epoch 3/10\n",
      "180000/180000 [==============================] - 104s - loss: 0.4009 - categorical_accuracy: 0.8205 - val_loss: 0.4003 - val_categorical_accuracy: 0.8185\n",
      "Epoch 4/10\n",
      "180000/180000 [==============================] - 105s - loss: 0.3784 - categorical_accuracy: 0.8323 - val_loss: 0.4050 - val_categorical_accuracy: 0.8196\n",
      "Epoch 5/10\n",
      "180000/180000 [==============================] - 104s - loss: 0.3548 - categorical_accuracy: 0.8457 - val_loss: 0.4158 - val_categorical_accuracy: 0.8194\n",
      "Epoch 6/10\n",
      "180000/180000 [==============================] - 104s - loss: 0.3330 - categorical_accuracy: 0.8562 - val_loss: 0.4154 - val_categorical_accuracy: 0.8177\n",
      "Epoch 7/10\n",
      "180000/180000 [==============================] - 104s - loss: 0.3146 - categorical_accuracy: 0.8650 - val_loss: 0.4287 - val_categorical_accuracy: 0.8133\n",
      "Epoch 8/10\n",
      "180000/180000 [==============================] - 104s - loss: 0.2966 - categorical_accuracy: 0.8734 - val_loss: 0.4758 - val_categorical_accuracy: 0.8089\n",
      "Shape of predict of test :  (200000, 2)\n",
      "/home/derricksu/pred/nocamma.csv\n",
      "length of vocab :  78930\n"
     ]
    }
   ],
   "source": [
    "from CRNN_config_nocomma import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "save_dict = False\n",
    "word_freq_path =  'word_freq.pk'\n",
    "\n",
    "load_word2vec = False\n",
    "word2vec_path = 'word2vec.bin'\n",
    "\n",
    "load_model_bool = False\n",
    "model_path = 'CRNN_1st.h5'\n",
    "\n",
    "nolabel = np.load(\"/home/derricksu/ML_data/hw4/train_nolabel.npy\")\n",
    "train_path = \"/home/derricksu/ML_data/hw4/train.npy\"\n",
    "train = np.load(train_path)\n",
    "test_path = \"/home/derricksu/ML_data/hw4/test.npy\"\n",
    "test = np.load(test_path)\n",
    "predict_path = \"/home/derricksu/pred/nocamma.csv\"\n",
    "\n",
    "\"\"\"\n",
    "## for homework\n",
    "train_path = sys.argv[1]\n",
    "train=load_data(train_path,train=True)\n",
    "\n",
    "nolabel_path = sys.argv[2]\n",
    "nolabel = load_nolabel(nolabel_path)\n",
    "\n",
    "test_path = sys.argv[1]\n",
    "test = load_data(test_path,train=False)\n",
    "\n",
    "predict_path = sys.argv[2]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Record frequency of each word\n",
    "word_freq=defaultdict(int)\n",
    "\n",
    "# nolabel\n",
    "sentence = []\n",
    "for row in nolabel:\n",
    "    x = text_to_wordlist(row,comma=False).split()\n",
    "    sentence.append(x)\n",
    "    for s in x:\n",
    "        word_freq[s]+=1\n",
    "\n",
    "print(\"After nolabel: %d\" % len(word_freq))\n",
    "\n",
    "# label\n",
    "X_data = train[:,1]\n",
    "y_data = train[:,0].astype('int')\n",
    "\n",
    "\n",
    "train_sentence = []\n",
    "\n",
    "for i,row in enumerate(X_data):\n",
    "    x = text_to_wordlist(row,comma=False).split()\n",
    "    train_sentence.append(x)\n",
    "    for s in x:\n",
    "        word_freq[s]+=1\n",
    "print(\"After label: %d\" % len(word_freq))\n",
    "\n",
    "test_sentence = []\n",
    "for i,row in enumerate(test[1::,1]): #第一列不為name\n",
    "    x = text_to_wordlist(row,comma=False).split()\n",
    "    test_sentence.append(x)\n",
    "    for s in x:\n",
    "        word_freq[s]+=1\n",
    "print(\"After test: %d\" % len(word_freq))\n",
    "\n",
    "\n",
    "print(\"word_freq is already\")\n",
    "\n",
    "\n",
    "# produce word2vec\n",
    "if not load_word2vec:\n",
    "    print(\"train word2vec...\") \n",
    "    # sg defines the training algorithm. By default (sg=0), CBOW is used. Otherwise (sg=1), skip-gram is employed. window=12\n",
    "    my_word2vec = Word2Vec(sentence + train_sentence + test_sentence, sg = 0,#window=15,\n",
    "                           iter=30, min_count=min_c,size=128,workers=16)\n",
    "    # summarize the loaded model\n",
    "    print(my_word2vec)\n",
    "    # summarize vocabulary\n",
    "    words = list(my_word2vec.wv.vocab)\n",
    "    #print(words)\n",
    "    # access vector for one word\n",
    "    print(my_word2vec['sentence'].shape)\n",
    "    # save model\n",
    "    #my_word2vec.save(word2vec_path)\n",
    "else:\n",
    "    print(\"load model...\") \n",
    "    my_word2vec = Word2Vec.load(word2vec_path)\n",
    "    #print(my_word2vec)\n",
    "\n",
    "vocab = dict([(k, v.index) for k, v in my_word2vec.wv.vocab.items()])\n",
    "weight_matrix = my_word2vec.wv.syn0 #word_to_vec\n",
    "print(\"Weight_matrix shape : \" , weight_matrix.shape)\n",
    "del my_word2vec\n",
    "print(\"word2vec is already.\")\n",
    "\n",
    "\n",
    "# word to idx of train\n",
    "train_word2idx=[]\n",
    "for row in train_sentence:\n",
    "    idx = []\n",
    "    for word in row:\n",
    "        if word_freq[word]>=min_c:\n",
    "            idx.append(vocab[word])\n",
    "    train_word2idx.append(idx)\n",
    "\n",
    "print(\"Length of train_sentence : \",len(train_sentence))\n",
    "print(\"Length of train_word2idx : \",len(train_word2idx))\n",
    "\n",
    "max_len = 0\n",
    "for row in train_word2idx:\n",
    "    if max_len <len(row):\n",
    "        max_len = len(row)\n",
    "print(\"Max length of train sentence : \",max_len)\n",
    "\n",
    "# word to idx of test\n",
    "test_word2idx=[]\n",
    "for row in test_sentence:\n",
    "    idx = []\n",
    "    for word in row:\n",
    "        if word_freq[word]>=min_c:\n",
    "            idx.append(vocab[word])\n",
    "    test_word2idx.append(idx)\n",
    "print(\"Length of test_sentence : \",len(test_sentence))\n",
    "print(\"Length of test_word2idx : \",len(test_word2idx))\n",
    "\n",
    "max_len = 0\n",
    "for row in train_word2idx:\n",
    "    if max_len <len(row):\n",
    "        max_len = len(row)\n",
    "print(\"Max length of test sentence : \",max_len)\n",
    "\n",
    "\n",
    "\n",
    "#import keras\n",
    "from keras import utils\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "Y_train = utils.to_categorical(y_data ,2)\n",
    "X_train = train_word2idx\n",
    "X_test = test_word2idx\n",
    "\n",
    "\n",
    "max_review_length = 100\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "\n",
    "n_batch = 256\n",
    "n_epoch = 10\n",
    "\n",
    "\n",
    "from keras.callbacks import EarlyStopping , History\n",
    "model = build(weight_matrix,vocab,max_review_length)\n",
    "earlystopping=EarlyStopping(monitor='val_categorical_accuracy', patience=3, verbose=0, mode='auto')\n",
    "history = History()\n",
    "\n",
    "hist_lstm_2 = model.fit(X_train , Y_train ,\n",
    "                      batch_size = n_batch,epochs=n_epoch,\n",
    "                      callbacks=[earlystopping,history],\n",
    "                      validation_split=0.1)\n",
    "\n",
    "pred_y = model.predict(X_test,batch_size=n_batch)\n",
    "print(\"Shape of predict of test : \",pred_y.shape)\n",
    "\n",
    "print(predict_path)\n",
    "with open(predict_path , \"w\" , encoding = \"utf-8\") as f :\n",
    "    f.write(\"id,label\\n\")\n",
    "    for i ,pre in enumerate(pred_y):\n",
    "        f.write( \"{0},{1}\\n\".format( i , np.argmax(pre) ) )\n",
    "    f.close()\n",
    "    \n",
    "print(\"length of vocab : \",len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nolabel2idx=[]\n",
    "for row in sentence:\n",
    "    idx = []\n",
    "    for word in row:\n",
    "        if word_freq[word]>=min_c:\n",
    "            idx.append(vocab[word])\n",
    "    if len(idx)<100:\n",
    "        nolabel2idx.append(idx)\n",
    "\n",
    "no_label_x = sequence.pad_sequences(nolabel2idx, maxlen=max_review_length)\n",
    "\n",
    "no_label_y = model.predict(no_label_x,batch_size=256)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_y = []\n",
    "for pred in no_label_y:\n",
    "    prob = pred[np.argmax(pred)]\n",
    "    if prob>0.7:\n",
    "        tag_y.append(np.argmax(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(511218, 980366)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(tag_y),len(tag_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
